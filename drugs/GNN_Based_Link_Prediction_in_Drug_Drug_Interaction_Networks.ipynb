{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOnGH8jsl5NL"
   },
   "source": [
    "# GNN-Based Link Prediction in Drug-Drug Interaction Networks\n",
    "Welcome! This colab serves as a tutorial for using Graph Machine Learning to perform Link Prediction in the drug-drug interaction dataset. Particularly, we focus on applying **GraphSage**, a type of **Graph Neural Network (GNN)**, to the `ogbl-ddi` dataset.\n",
    "\n",
    "Over the course of this colab, we will begin development from the ground-up: from downloading the dataset, to writing training code to prepare a base model using [PyTorch Geometric (PyG)](https://pytorch-geometric.readthedocs.io/en/latest/), to implementing increasingly advanced techniques to try and improve our performance. We would strongly encourage you to make use of GPU runtime as you go through this notebook. Now, let's get started!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W57vvc3jEscl"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzB9tYiDGcts"
   },
   "source": [
    "### Installation\n",
    "\n",
    "We first will install PyG as well as [ogb](https://github.com/snap-stanford/ogb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9Tgj6bFGf5E",
    "outputId": "207c29ea-eab4-4bf6-cb24-247e60409b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.3.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNe4asLBGtGn",
    "outputId": "e7716fbf-34ed-49d3-e0d8-50c4c4b25cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
      "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
      "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
      "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
      "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
      "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (1.3.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.1.5)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.62.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.1)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.10.0+cu111)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
      "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
    "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
    "# !pip install torch-geometric\n",
    "# !pip install ogb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wP4RsBSkG6uA"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LHZchSNMEG7U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling, convert, to_dense_adj\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EpUQKewJr3V"
   },
   "source": [
    "## Dataset\n",
    "As mentioned above, the dataset that we are working with is [ogbl-ddi](https://ogb.stanford.edu/docs/linkprop/#ogbl-ddi). Briefly, in the homogenous, feature-less, undirected graph, each node represents a drug. Edges between nodes represent interactions between the drugs, where the joint effect of taking both drugs is markedly different than the expected effects if either drug was taken independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktfQQiDzJuUp"
   },
   "source": [
    "### Installation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgmXT6IaSOyN"
   },
   "source": [
    "The `ogb` library makes downloading an official ogb dataset, like ogbl-ddi, incredibly easy.\n",
    "\n",
    "Below, we download the (non-sparse) version of the dataset and explore it using NetworkX, a popular Python library for working with graphs/networks. To do so, we leverage PyG utilities to convert the dataset into a NetworkX graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tOlunvuJtMs",
    "outputId": "1f50c961-c4bb-4c7b-d57b-97f6a2800e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/linkproppred/ddi.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.04 GB: 100%|███████████████████████████████████████████████████████████████| 46/46 [00:18<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/ddi.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 30.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 596.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "data = dataset[0]\n",
    "G = convert.to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xicAHoShr6t4"
   },
   "source": [
    "We know gather some statistics about the graph using NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whiT-BQ9Tnh0",
    "outputId": "d4de6236-b301-4171-869e-7e8ce152a37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogbl-ddi has 4267 nodes and 1067911 edges, with an average node degree of 501\n"
     ]
    }
   ],
   "source": [
    "num_nodes, num_edges = G.number_of_nodes(), G.number_of_edges()\n",
    "print(f'ogbl-ddi has {num_nodes} nodes and {num_edges} edges, with an average node degree of {round(2 * num_edges / num_nodes)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVFhrsILsJOv"
   },
   "source": [
    "We wrap up our exploration of this graph by visualizing a subgraph of it (feel free to adjust `num_nodes_to_sample` to see more or less of the graph, though anything above 1000 will take a bit of time to render)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "sNNN3VpQLGVI",
    "outputId": "967c8644-b1be-469e-bcb9-bcb6f90fb70a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154431/1798638830.py:2: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes = random.sample(G.nodes, num_nodes_to_sample)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_nodes_to_sample = 100\n",
    "sampled_nodes = random.sample(G.nodes, num_nodes_to_sample)\n",
    "sampled_graph = G.subgraph(sampled_nodes)\n",
    "nx.draw(sampled_graph, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5r83nHlZCGR"
   },
   "source": [
    "Now, it's time to download the sparse version of the graph that we are actually going to make use of when developing models. We will use this version of the dataset to get our edge splits (train, validation, test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQdctAmeL4gt",
    "outputId": "2300abd6-7c7b-4625-b6ca-9c36ea22f0aa"
   },
   "outputs": [],
   "source": [
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi',\n",
    "                                     transform=T.ToSparseTensor())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data = dataset[0]\n",
    "adj_t = data.adj_t.to(device)\n",
    "split_edge = dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSuG-U_mHBID"
   },
   "source": [
    "Finally, as ogbl-ddi has no node features, we will initialize our own (constant) initial embeddings for all the nodes. We will make use of `emb` once we get into the thick of training our own model below. Note, to be more inductive, we have opted not to make our embeddings learned parameters, unlike prior work with ogbl-ddi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rqFrZatjZH4H"
   },
   "outputs": [],
   "source": [
    "emb = torch.ones(num_nodes, 1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKPW29aNAC3Z"
   },
   "source": [
    "## Base GraphSage Model\n",
    "\n",
    "Now that we have our dataset downloaded, we can begin building our baseline model using PyG!\n",
    "\n",
    "Our base model consists of (1) the GraphSage GNN for generating node embeddings (2) a basic LinkPredictor that simply does a dot product between the two node embeddings followed by a sigmoid. Notice that we are leveraging the built-in [SAGEConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) layer from PyG, which allows us to quickly get our model up and running. Our base model is heavily inspired by the ogb sample code for ogbl-ddi, which can be found here: https://github.com/snap-stanford/ogb/blob/master/examples/linkproppred/ddi/gnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zPbkWxBrAF-d"
   },
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout, aggr=\"add\"):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, normalize=True, aggr=aggr))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "class DotProductLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DotProductLinkPredictor, self).__init__()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        out = (x_i*x_j).sum(-1)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhUkI6C-Ho9F"
   },
   "source": [
    "To help familiarize readers with how the GNN and LinkPredictor work, below we apply the untrained model to the training graph and use the output node embeddings to make link predictions. While the results will be terrible, it does give a good sense of how to make use of these PyG-based models.\n",
    "\n",
    "We have chosen a `hidden_dimension` / embedding dimensionality of 256. As the diameter of the graph (computed using NetworkX [diameter](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.distance_measures.diameter.html) method; not included in this Colab as it takes a long time to run) is 5 and a general rule of thumb says to keep the receptive field of the GNN slightly higher than that, we have chosen a 7-layer GraphSage model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1qq7xYcDf7X",
    "outputId": "4c2261d2-8e2d-4801-e3a1-ea302476f1d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/overfero/.local/lib/python3.10/site-packages/torch_sparse/tensor.py:574: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7310, 0.7311, 0.7311,\n",
       "        0.7311], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = DotProductLinkPredictor().to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(emb, adj_t)\n",
    "\n",
    "# Randomly sample some training edges and pass them through our basic predictor\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))[:10]\n",
    "edges = split_edge['train']['edge'][idx].t()\n",
    "predictor(h[edges[0]], h[edges[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBCZGBy_3S0G"
   },
   "source": [
    "##Training and Evaluation\n",
    "\n",
    "Now we will define functions that we will use for training and evaluating our models! Once again, we took much inspiration from https://github.com/snap-stanford/ogb/blob/master/examples/linkproppred/ddi/gnn.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgm4b9LgjNpg"
   },
   "source": [
    "### Training Drivers\n",
    "We leverage a fairly standard PyTorch training loop. For each batch of positive edges from our initial training split, we leverage PyG's [negative_sampling](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html?highlight=negative_sampling#torch_geometric.utils.negative_sampling) utility to create an equivalently sized batch of negative edges (i.e. edges NOT present in the training graph). The complete training batch thus contains an equal amount of positive and negative edges.\n",
    "\n",
    "For every batch, we generate node embeddings using all the training edges. We then make link predictions for the current batch and compute our loss, from which we backpropagate  to update our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TqXKRXKqI5Gn"
   },
   "outputs": [],
   "source": [
    "def create_train_batch(all_pos_train_edges, perm, edge_index):\n",
    "    # First, we get our positive edges, reshaping them to the form (2, hidden_dimension)\n",
    "    pos_edges = all_pos_train_edges[perm].t().to(device)\n",
    "\n",
    "    # We then sample the negative edges using PyG functionality\n",
    "    neg_edges = negative_sampling(edge_index, num_nodes=num_nodes,\n",
    "                                  num_neg_samples=perm.shape[0], method='dense').to(device)\n",
    "\n",
    "    # Our training batch is just the positive edges concatanted with the negative ones\n",
    "    train_edge = torch.cat([pos_edges, neg_edges], dim=1)\n",
    "\n",
    "    # Our labels are all 1 for the positive edges and 0 for the negative ones\n",
    "    pos_label = torch.ones(pos_edges.shape[1], )\n",
    "    neg_label = torch.zeros(neg_edges.shape[1], )\n",
    "    train_label = torch.cat([pos_label, neg_label], dim=0).to(device)\n",
    "\n",
    "    return train_edge, train_label\n",
    "\n",
    "def train(model, predictor, x, adj_t, split_edge, loss_fn, optimizer, batch_size, num_epochs, edge_model=False, spd=None):\n",
    "  # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
    "  row, col, edge_attr = adj_t.t().coo()\n",
    "  edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "  model.train()\n",
    "  predictor.train()\n",
    "\n",
    "  model.reset_parameters()\n",
    "  predictor.reset_parameters()\n",
    "\n",
    "  all_pos_train_edges = split_edge['train']['edge']\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_total_loss = 0\n",
    "    for perm in DataLoader(range(all_pos_train_edges.shape[0]), batch_size,\n",
    "                           shuffle=True):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
    "\n",
    "      # Use the GNN to generate node embeddings\n",
    "      if edge_model:\n",
    "        h = model(x, edge_index, spd)\n",
    "      else:\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "      # Get predictions for our batch and compute the loss\n",
    "      preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
    "      loss = loss_fn(preds, train_label)\n",
    "\n",
    "      epoch_total_loss += loss.item()\n",
    "\n",
    "      # Update our parameters\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "    print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyJykFrgjRu5"
   },
   "source": [
    "### Evaluation Drivers\n",
    "Our evaluation code is also fairly standard PyTorch. As our validation and test splits from ogb already come with negative edges, we are able to easily leverage them instead of generating our own.\n",
    "\n",
    "Like with the training code, we use the training graph to generate node embeddings using our GNN. We then calculate predictions using the LinkPredictor for our positive and negative edges. Although we calculate accuracy ourselves, we leverage the [Evaluator](https://github.com/snap-stanford/ogb/blob/68a303f320220cda859e83e3a8660f2b9debedf6/ogb/linkproppred/evaluate.py#L11) provided by the ogb library for ogbl-ddi to calculate Hits@K. Though we demonstrate how to calculate Hits@K for several values of K, in keeping with prior work, we focus on Hits@20 as our primary metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c94k9T5F71i",
    "outputId": "6879368d-b474-4630-d4ff-8a00564250a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ddi\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred, label):\n",
    "  pred_rounded = torch.round(pred)\n",
    "  accu = torch.eq(pred_rounded, label).sum() / label.shape[0]\n",
    "  accu = round(accu.item(), 4)\n",
    "  return accu\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size, edge_model=False, spd=None):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    if edge_model:\n",
    "        # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index\n",
    "        row, col, edge_attr = adj_t.t().coo()\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        h = model(x, edge_index, spd)\n",
    "    else:\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "    pos_eval_edge = split_edge['edge'].to(device)\n",
    "    neg_eval_edge = split_edge['edge_neg'].to(device)\n",
    "\n",
    "    pos_eval_preds = []\n",
    "    for perm in DataLoader(range(pos_eval_edge.shape[0]), batch_size):\n",
    "        edge = pos_eval_edge[perm].t()\n",
    "        pos_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_eval_pred = torch.cat(pos_eval_preds, dim=0)\n",
    "\n",
    "    neg_eval_preds = []\n",
    "    for perm in DataLoader(range(neg_eval_edge.size(0)), batch_size):\n",
    "        edge = neg_eval_edge[perm].t()\n",
    "        neg_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_eval_pred = torch.cat(neg_eval_preds, dim=0)\n",
    "\n",
    "    total_preds = torch.cat((pos_eval_pred, neg_eval_pred), dim=0)\n",
    "    labels = torch.cat((torch.ones_like(pos_eval_pred), torch.zeros_like(neg_eval_pred)), dim=0)\n",
    "    acc = accuracy(total_preds, labels)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30, 40, 50]:\n",
    "        evaluator.K = K\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_eval_pred,\n",
    "            'y_pred_neg': neg_eval_pred,\n",
    "        })[f'hits@{K}']\n",
    "        results[f'Hits@{K}'] = (valid_hits)\n",
    "    results['Accuracy'] = acc\n",
    "\n",
    "    return results\n",
    "eval = Evaluator(name='ogbl-ddi')\n",
    "# ogb Evaluators can be invoked to get their expected format\n",
    "print(eval.expected_input_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XODWt6H9ja4y"
   },
   "source": [
    "### Train and Evaluate Baseline Model\n",
    "Now we are ready to kick-off training of our base model and evaluate it with our validation set. As we will do with all of our models, we make use of the Adam optimizer and Binary Cross-Entropy loss. Readers should feel free to experiment with other optimizers/loss functions as they see fit.\n",
    "\n",
    "*This cell will take around 2-3 minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNhlaEN5i7Ac",
    "outputId": "fdebb507-bc92-4a7f-dd19-111ba447eb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 11.6038\n",
      "Epoch 1 has loss 10.2476\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m      2\u001b[0m             \u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())  \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;28mlist\u001b[39m(predictor\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m test(model, predictor, emb, adj_t, split_edge[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m], Evaluator(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mogbl-ddi\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m64\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 52\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, predictor, x, adj_t, split_edge, loss_fn, optimizer, batch_size, num_epochs, edge_model, spd)\u001b[0m\n\u001b[1;32m     49\u001b[0m epoch_total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Update our parameters\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     54\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(predictor\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 30)\n",
    "test(model, predictor, emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChsBdirvr7UQ"
   },
   "source": [
    "Our base model performs pretty poorly: while accuracy may be decent, Hits@K reveal that it does not do a good job distinguishing negative edges from positive ones.\n",
    "\n",
    "Our basic model is just not expressive enough. But we can now guide readers through how the basic model can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rERX814anEIb"
   },
   "source": [
    "## Model Enhancements\n",
    "With our baseline model successfully trained, we now shift our attention to improving the model itself using a variety of different Graph Machine Learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "615i5M5ELx_P"
   },
   "source": [
    "### Robust GNN\n",
    "Our basic GraphSage implementation (using 'add' aggregation) was little more than successive GNN layers stacked on top of each other.\n",
    "\n",
    "Just adding more layers onto a GNN can get detrimental, as we can just end up with embeddings all being the same. However, PyG allows us to easily enhance our GNN model in other ways, such as by adding skip-connections between layers, batch normalization, and even post-processing layers. Let's put some of these ideas to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSS9Es437yfv"
   },
   "source": [
    "#### Skip-Connection\n",
    "\n",
    "A skip-connection, in theory, allows us to have more layers in our GNN. This would allow us to incorporate information from larger k-hop neighborhoods, while somewhat mitigating the risk of over-smoothing node embeddings.\n",
    "\n",
    "We can quickly build upon our base `SAGE` model to include skip-connections, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ674Bj6Qbfp"
   },
   "outputs": [],
   "source": [
    "class SkipConnSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SkipConnSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_dimension, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "        self.convs.append(SAGEConv(hidden_dimension, out_channels, normalize=True, aggr=\"add\"))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        prev_x = None\n",
    "        for i in range(len(self.convs) - 1):\n",
    "          prev_x = x\n",
    "          x = self.convs[i](x, adj_t)\n",
    "          # Skip Connection\n",
    "          if i > 0:\n",
    "            x = x + prev_x\n",
    "          x = F.relu(x)\n",
    "          x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raPR8Ui0heIF"
   },
   "source": [
    "With our `SkipConnSAGE` model defined, we can now initiate its training end evaluation, just as we did with `SAGE` before. This time, we will use 10 `SAGEConv` layers.\n",
    "\n",
    "*This cell will take around 10 minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpC_0EdmVUlb",
    "outputId": "7cd16724-3c96-4a71-dd84-fef9938e2e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 12.1889\n",
      "Epoch 1 has loss 10.7741\n",
      "Epoch 2 has loss 10.4716\n",
      "Epoch 3 has loss 10.3604\n",
      "Epoch 4 has loss 10.3707\n",
      "Epoch 5 has loss 10.2429\n",
      "Epoch 6 has loss 10.2347\n",
      "Epoch 7 has loss 10.1862\n",
      "Epoch 8 has loss 10.1846\n",
      "Epoch 9 has loss 10.1771\n",
      "Epoch 10 has loss 10.1501\n",
      "Epoch 11 has loss 10.1961\n",
      "Epoch 12 has loss 10.2139\n",
      "Epoch 13 has loss 10.1737\n",
      "Epoch 14 has loss 10.1412\n",
      "Epoch 15 has loss 10.1316\n",
      "Epoch 16 has loss 10.138\n",
      "Epoch 17 has loss 10.1327\n",
      "Epoch 18 has loss 10.1366\n",
      "Epoch 19 has loss 10.069\n",
      "Epoch 20 has loss 10.0609\n",
      "Epoch 21 has loss 10.0815\n",
      "Epoch 22 has loss 10.0427\n",
      "Epoch 23 has loss 10.0846\n",
      "Epoch 24 has loss 10.0922\n",
      "Epoch 25 has loss 10.0285\n",
      "Epoch 26 has loss 9.9897\n",
      "Epoch 27 has loss 9.9965\n",
      "Epoch 28 has loss 9.9828\n",
      "Epoch 29 has loss 10.0205\n",
      "Epoch 30 has loss 9.9745\n",
      "Epoch 31 has loss 9.958\n",
      "Epoch 32 has loss 9.9662\n",
      "Epoch 33 has loss 9.9283\n",
      "Epoch 34 has loss 9.8914\n",
      "Epoch 35 has loss 9.8758\n",
      "Epoch 36 has loss 9.8331\n",
      "Epoch 37 has loss 9.7715\n",
      "Epoch 38 has loss 9.8131\n",
      "Epoch 39 has loss 9.7702\n",
      "Epoch 40 has loss 9.7698\n",
      "Epoch 41 has loss 9.765\n",
      "Epoch 42 has loss 9.6816\n",
      "Epoch 43 has loss 9.8294\n",
      "Epoch 44 has loss 9.7449\n",
      "Epoch 45 has loss 9.7188\n",
      "Epoch 46 has loss 9.7117\n",
      "Epoch 47 has loss 9.6589\n",
      "Epoch 48 has loss 9.5775\n",
      "Epoch 49 has loss 9.5638\n",
      "Epoch 50 has loss 9.5556\n",
      "Epoch 51 has loss 9.5837\n",
      "Epoch 52 has loss 9.5209\n",
      "Epoch 53 has loss 9.5106\n",
      "Epoch 54 has loss 9.4943\n",
      "Epoch 55 has loss 9.5158\n",
      "Epoch 56 has loss 9.5134\n",
      "Epoch 57 has loss 9.4868\n",
      "Epoch 58 has loss 9.4957\n",
      "Epoch 59 has loss 9.4714\n",
      "Epoch 60 has loss 9.4834\n",
      "Epoch 61 has loss 9.4949\n",
      "Epoch 62 has loss 9.4858\n",
      "Epoch 63 has loss 9.4556\n",
      "Epoch 64 has loss 9.4441\n",
      "Epoch 65 has loss 9.4559\n",
      "Epoch 66 has loss 9.4524\n",
      "Epoch 67 has loss 9.4449\n",
      "Epoch 68 has loss 9.4682\n",
      "Epoch 69 has loss 9.4394\n",
      "Epoch 70 has loss 9.4531\n",
      "Epoch 71 has loss 9.4471\n",
      "Epoch 72 has loss 9.4326\n",
      "Epoch 73 has loss 9.4338\n",
      "Epoch 74 has loss 9.4366\n",
      "Epoch 75 has loss 9.4382\n",
      "Epoch 76 has loss 9.4326\n",
      "Epoch 77 has loss 9.4573\n",
      "Epoch 78 has loss 9.4413\n",
      "Epoch 79 has loss 9.431\n",
      "Epoch 80 has loss 9.4223\n",
      "Epoch 81 has loss 9.4184\n",
      "Epoch 82 has loss 9.4161\n",
      "Epoch 83 has loss 9.4118\n",
      "Epoch 84 has loss 9.4208\n",
      "Epoch 85 has loss 9.4214\n",
      "Epoch 86 has loss 9.4094\n",
      "Epoch 87 has loss 9.4075\n",
      "Epoch 88 has loss 9.4055\n",
      "Epoch 89 has loss 9.3979\n",
      "Epoch 90 has loss 9.3966\n",
      "Epoch 91 has loss 9.4072\n",
      "Epoch 92 has loss 9.3981\n",
      "Epoch 93 has loss 9.4076\n",
      "Epoch 94 has loss 9.3992\n",
      "Epoch 95 has loss 9.4093\n",
      "Epoch 96 has loss 9.3954\n",
      "Epoch 97 has loss 9.4052\n",
      "Epoch 98 has loss 9.4023\n",
      "Epoch 99 has loss 9.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5671,\n",
       " 'Hits@10': 0.0,\n",
       " 'Hits@20': 0.0,\n",
       " 'Hits@30': 0.0,\n",
       " 'Hits@40': 0.0,\n",
       " 'Hits@50': 0.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize our enhanced model and LinkPredictor\n",
    "model = SkipConnSAGE(1, hidden_dimension, hidden_dimension, 10, 0.5).to(device)\n",
    "predictor = DotProductLinkPredictor().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 100)\n",
    "test(model, predictor, emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INSfEMJAiFi6"
   },
   "source": [
    "Alas, skip-connections actually seem to be deterimental for ogbl-ddi. Even reducing the number of GNN layers back down to 7 (or even 5) does not significantly improve performance. An in-depth analysis of what went wrong here can be found in the corresponding Medium post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zW9wuh-8o08"
   },
   "source": [
    "#### Post-Processing Layers\n",
    "We can also try including post-processing layers in our GNN that do not pass messages, but simply apply a neural network to the embeddings. This can be convenient when the embeddings need to be used in a downstream task, such as the link prediction we wish to perform.\n",
    "\n",
    "Below, we augment our base `SAGE` model with additional post-processing linear layers that are applied to the output of the GNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjUtWuXT8w0m"
   },
   "outputs": [],
   "source": [
    "class PostProcessSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, out_channels, num_conv_layers,\n",
    "                 num_linear_layers, dropout):\n",
    "        super(PostProcessSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "        for _ in range(num_conv_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_dimension, hidden_dimension, normalize=True, aggr=\"add\"))\n",
    "\n",
    "        for _ in range(num_linear_layers - 1):\n",
    "            self.lins.append(torch.nn.Linear(hidden_dimension, hidden_dimension))\n",
    "        self.lins.append(torch.nn.Linear(hidden_dimension, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "\n",
    "        # Post-process\n",
    "        for lin in self.lins[:-1]:\n",
    "          x = lin(x)\n",
    "          x = F.relu(x)\n",
    "        x = self.lins[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mS29LRDlZV2"
   },
   "source": [
    "Let's now train and evaluate `PostProcessSAGE`, with 4 layers of post-processing.\n",
    "\n",
    "*This cell will take around 10 minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iukxLZcnANXX",
    "outputId": "8deea290-bf6f-494f-f721-0671f0e6dddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 11.8955\n",
      "Epoch 1 has loss 11.7832\n",
      "Epoch 2 has loss 11.4847\n",
      "Epoch 3 has loss 11.3136\n",
      "Epoch 4 has loss 10.956\n",
      "Epoch 5 has loss 11.0432\n",
      "Epoch 6 has loss 11.2958\n",
      "Epoch 7 has loss 10.7023\n",
      "Epoch 8 has loss 11.0348\n",
      "Epoch 9 has loss 9.8048\n",
      "Epoch 10 has loss 9.8009\n",
      "Epoch 11 has loss 9.7332\n",
      "Epoch 12 has loss 9.4423\n",
      "Epoch 13 has loss 9.3573\n",
      "Epoch 14 has loss 9.3478\n",
      "Epoch 15 has loss 9.3611\n",
      "Epoch 16 has loss 9.3328\n",
      "Epoch 17 has loss 9.3153\n",
      "Epoch 18 has loss 9.3002\n",
      "Epoch 19 has loss 9.3038\n",
      "Epoch 20 has loss 9.2778\n",
      "Epoch 21 has loss 9.2568\n",
      "Epoch 22 has loss 9.2601\n",
      "Epoch 23 has loss 9.229\n",
      "Epoch 24 has loss 9.1741\n",
      "Epoch 25 has loss 9.1549\n",
      "Epoch 26 has loss 9.1185\n",
      "Epoch 27 has loss 9.0542\n",
      "Epoch 28 has loss 9.0445\n",
      "Epoch 29 has loss 9.0405\n",
      "Epoch 30 has loss 9.0694\n",
      "Epoch 31 has loss 9.0329\n",
      "Epoch 32 has loss 9.0334\n",
      "Epoch 33 has loss 9.0456\n",
      "Epoch 34 has loss 9.1283\n",
      "Epoch 35 has loss 9.0407\n",
      "Epoch 36 has loss 9.0201\n",
      "Epoch 37 has loss 9.0341\n",
      "Epoch 38 has loss 9.0613\n",
      "Epoch 39 has loss 9.0691\n",
      "Epoch 40 has loss 9.0345\n",
      "Epoch 41 has loss 9.0147\n",
      "Epoch 42 has loss 9.0313\n",
      "Epoch 43 has loss 9.0302\n",
      "Epoch 44 has loss 9.0545\n",
      "Epoch 45 has loss 9.022\n",
      "Epoch 46 has loss 9.0255\n",
      "Epoch 47 has loss 8.9726\n",
      "Epoch 48 has loss 8.9821\n",
      "Epoch 49 has loss 8.923\n",
      "Epoch 50 has loss 8.9857\n",
      "Epoch 51 has loss 8.7749\n",
      "Epoch 52 has loss 8.9225\n",
      "Epoch 53 has loss 9.0089\n",
      "Epoch 54 has loss 8.9693\n",
      "Epoch 55 has loss 8.9786\n",
      "Epoch 56 has loss 8.7511\n",
      "Epoch 57 has loss 8.6617\n",
      "Epoch 58 has loss 8.5233\n",
      "Epoch 59 has loss 8.6094\n",
      "Epoch 60 has loss 8.8068\n",
      "Epoch 61 has loss 8.5957\n",
      "Epoch 62 has loss 8.4958\n",
      "Epoch 63 has loss 8.7349\n",
      "Epoch 64 has loss 8.4728\n",
      "Epoch 65 has loss 8.4911\n",
      "Epoch 66 has loss 8.5847\n",
      "Epoch 67 has loss 8.5311\n",
      "Epoch 68 has loss 8.4577\n",
      "Epoch 69 has loss 8.4746\n",
      "Epoch 70 has loss 8.4913\n",
      "Epoch 71 has loss 8.3453\n",
      "Epoch 72 has loss 8.2723\n",
      "Epoch 73 has loss 8.2541\n",
      "Epoch 74 has loss 8.4278\n",
      "Epoch 75 has loss 8.2272\n",
      "Epoch 76 has loss 8.325\n",
      "Epoch 77 has loss 8.3011\n",
      "Epoch 78 has loss 8.3898\n",
      "Epoch 79 has loss 8.2434\n",
      "Epoch 80 has loss 8.1967\n",
      "Epoch 81 has loss 8.1836\n",
      "Epoch 82 has loss 8.2644\n",
      "Epoch 83 has loss 8.3151\n",
      "Epoch 84 has loss 8.3506\n",
      "Epoch 85 has loss 8.4799\n",
      "Epoch 86 has loss 8.3937\n",
      "Epoch 87 has loss 8.2\n",
      "Epoch 88 has loss 8.1569\n",
      "Epoch 89 has loss 8.1882\n",
      "Epoch 90 has loss 8.2213\n",
      "Epoch 91 has loss 8.3029\n",
      "Epoch 92 has loss 8.2443\n",
      "Epoch 93 has loss 8.2057\n",
      "Epoch 94 has loss 8.1096\n",
      "Epoch 95 has loss 8.2293\n",
      "Epoch 96 has loss 8.1811\n",
      "Epoch 97 has loss 8.1364\n",
      "Epoch 98 has loss 8.2253\n",
      "Epoch 99 has loss 8.2387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7972,\n",
       " 'Hits@10': 0.06408018638239855,\n",
       " 'Hits@20': 0.11936564061458248,\n",
       " 'Hits@30': 0.12729887855928204,\n",
       " 'Hits@40': 0.14792230071391652,\n",
       " 'Hits@50': 0.15880709271925028}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PostProcessSAGE(1, hidden_dimension, hidden_dimension, 7, 4, 0.5).to(device)\n",
    "predictor = DotProductLinkPredictor().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 100)\n",
    "test(model, predictor, emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zt0uPafKRXA"
   },
   "source": [
    "We see a modest performance boost over the baseline model! In particular, Hits@20 is now non-zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRntMuT2r4V1"
   },
   "source": [
    "### Enhance LinkPredictor\n",
    "\n",
    "Up until now, we have used a parameter-less LinkPredictor that just does a dot product between embeddings. However, given the performance boost we saw by performing post-processing on our node embeddings to make them better suited for link prediction, a logical next step would be to make our LinkPredictor its own neural network that we train alongside the GNN that generates the embeddings.\n",
    "\n",
    "Below, we define such a `NeuralLinkPredictor`, which is just a small neural network created using traditional PyTorch modules. We once again heavily drew inspiration from https://github.com/snap-stanford/ogb/blob/master/examples/linkproppred/ddi/gnn.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibNAeI-mnTSk"
   },
   "outputs": [],
   "source": [
    "class NeuralLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(NeuralLinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1eD2acNtSpq"
   },
   "source": [
    "Let's see the benefits of using our `NeuralLinkPredictor` with our original `SAGE` model. We will kick-off training and evaluation with a 4-layer `NeuralLinkPredictor`.\n",
    "\n",
    "*This cell will take around 10 minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qHhJHzsth7v",
    "outputId": "a8bf3c58-1fd5-46be-a988-b13102aef3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 12.0659\n",
      "Epoch 1 has loss 10.0522\n",
      "Epoch 2 has loss 9.7123\n",
      "Epoch 3 has loss 9.7045\n",
      "Epoch 4 has loss 9.4551\n",
      "Epoch 5 has loss 9.2476\n",
      "Epoch 6 has loss 8.8489\n",
      "Epoch 7 has loss 7.8619\n",
      "Epoch 8 has loss 7.4604\n",
      "Epoch 9 has loss 7.3953\n",
      "Epoch 10 has loss 6.9876\n",
      "Epoch 11 has loss 6.5006\n",
      "Epoch 12 has loss 6.1975\n",
      "Epoch 13 has loss 5.7866\n",
      "Epoch 14 has loss 5.8142\n",
      "Epoch 15 has loss 5.7181\n",
      "Epoch 16 has loss 5.4725\n",
      "Epoch 17 has loss 5.3401\n",
      "Epoch 18 has loss 5.358\n",
      "Epoch 19 has loss 5.2417\n",
      "Epoch 20 has loss 5.1477\n",
      "Epoch 21 has loss 5.0085\n",
      "Epoch 22 has loss 5.0462\n",
      "Epoch 23 has loss 5.1386\n",
      "Epoch 24 has loss 4.977\n",
      "Epoch 25 has loss 4.8947\n",
      "Epoch 26 has loss 4.8313\n",
      "Epoch 27 has loss 4.8141\n",
      "Epoch 28 has loss 4.7011\n",
      "Epoch 29 has loss 4.7146\n",
      "Epoch 30 has loss 4.6313\n",
      "Epoch 31 has loss 4.5789\n",
      "Epoch 32 has loss 4.5772\n",
      "Epoch 33 has loss 4.5209\n",
      "Epoch 34 has loss 4.5832\n",
      "Epoch 35 has loss 4.6198\n",
      "Epoch 36 has loss 4.4905\n",
      "Epoch 37 has loss 4.3566\n",
      "Epoch 38 has loss 4.4068\n",
      "Epoch 39 has loss 4.4023\n",
      "Epoch 40 has loss 4.3603\n",
      "Epoch 41 has loss 4.277\n",
      "Epoch 42 has loss 4.2358\n",
      "Epoch 43 has loss 4.1912\n",
      "Epoch 44 has loss 4.1838\n",
      "Epoch 45 has loss 4.0986\n",
      "Epoch 46 has loss 4.0516\n",
      "Epoch 47 has loss 4.2285\n",
      "Epoch 48 has loss 4.0057\n",
      "Epoch 49 has loss 3.9418\n",
      "Epoch 50 has loss 3.9426\n",
      "Epoch 51 has loss 4.0254\n",
      "Epoch 52 has loss 3.979\n",
      "Epoch 53 has loss 3.9006\n",
      "Epoch 54 has loss 3.8538\n",
      "Epoch 55 has loss 3.8636\n",
      "Epoch 56 has loss 3.8304\n",
      "Epoch 57 has loss 3.7983\n",
      "Epoch 58 has loss 3.6998\n",
      "Epoch 59 has loss 3.7305\n",
      "Epoch 60 has loss 3.7628\n",
      "Epoch 61 has loss 3.6822\n",
      "Epoch 62 has loss 3.6603\n",
      "Epoch 63 has loss 3.6517\n",
      "Epoch 64 has loss 3.6268\n",
      "Epoch 65 has loss 3.6038\n",
      "Epoch 66 has loss 3.5455\n",
      "Epoch 67 has loss 3.5667\n",
      "Epoch 68 has loss 3.5908\n",
      "Epoch 69 has loss 3.4779\n",
      "Epoch 70 has loss 3.4781\n",
      "Epoch 71 has loss 3.5915\n",
      "Epoch 72 has loss 3.4846\n",
      "Epoch 73 has loss 3.4877\n",
      "Epoch 74 has loss 3.4438\n",
      "Epoch 75 has loss 3.3884\n",
      "Epoch 76 has loss 3.4542\n",
      "Epoch 77 has loss 3.4188\n",
      "Epoch 78 has loss 3.3436\n",
      "Epoch 79 has loss 3.3031\n",
      "Epoch 80 has loss 3.3525\n",
      "Epoch 81 has loss 3.3446\n",
      "Epoch 82 has loss 3.292\n",
      "Epoch 83 has loss 3.3535\n",
      "Epoch 84 has loss 3.2822\n",
      "Epoch 85 has loss 3.2249\n",
      "Epoch 86 has loss 3.293\n",
      "Epoch 87 has loss 3.2189\n",
      "Epoch 88 has loss 3.2082\n",
      "Epoch 89 has loss 3.2604\n",
      "Epoch 90 has loss 3.2126\n",
      "Epoch 91 has loss 3.1842\n",
      "Epoch 92 has loss 3.1459\n",
      "Epoch 93 has loss 3.2264\n",
      "Epoch 94 has loss 3.1712\n",
      "Epoch 95 has loss 3.1706\n",
      "Epoch 96 has loss 3.1189\n",
      "Epoch 97 has loss 3.1457\n",
      "Epoch 98 has loss 3.2168\n",
      "Epoch 99 has loss 3.1659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9396,\n",
       " 'Hits@10': 0.1789660571283027,\n",
       " 'Hits@20': 0.32165197132347983,\n",
       " 'Hits@30': 0.40468503022720975,\n",
       " 'Hits@40': 0.4638209889953479,\n",
       " 'Hits@50': 0.4911715572069609}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = NeuralLinkPredictor(hidden_dimension, hidden_dimension, 1, 4, 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 100)\n",
    "test(model, predictor, emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYVSTkc21tJl"
   },
   "source": [
    "With 100 epochs, we get a considerable jump in performance, both on accuracy and Hits@K!. Clearly, a more expressive LinkPredictor can take these embeddings generated by our basic GNN and start making reasonably good predictions. However, our Hits@K is still fairly low, meaning we still have a considerable amount of negative edges scoring very high. We still have room for exploration!\n",
    "\n",
    "Also, it's worth noting that although we chose to pass the element-wise product of the two node embeddings through the neural network for simplicity, a potentially better option could be to pass the concatenation of the two embeddings through instead. Experimenting with such a configuration, and others, can be easily done from our Colab and is left as an exercise to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1So5GWYrSLmo"
   },
   "source": [
    "## Node Feature Augmentation\n",
    "While with the `NeuralLinkPredictor` we were able to achieve reasonable accuracy, we were still ranking many negative links fairly highly, causing our Hits@20 scores to fall.\n",
    "\n",
    "As we saw above, trying to improve our GNN model, itself, gave mixed results. In a situation like this, with a homogenous graph with no features that seems to be hitting a wall with just GNN tweaks, we may instead want to augment our initial nodes with features we calculate on our own. Having distinct input features for each node may allow our GNN to produce better embeddings that allow for better link prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fogQbsll_pkC"
   },
   "source": [
    "### Generating Initial Node Features\n",
    "Picking the right features is a delicate art that requires an intricate search. For demonstration purposes, we have chosen a handful of common features that can be easily calculated for each node using NetworkX. Below, we use those features to create our new initial features.\n",
    "\n",
    "*This cell will take around 5-10 minutes to run. In particular, using a higher value of k for our approximation of betweenness centrality will take more time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F08yeyhzSy8A"
   },
   "outputs": [],
   "source": [
    "# Calc the node stats that we are going to utilize\n",
    "pagerank = nx.algorithms.link_analysis.pagerank_alg.pagerank(G)\n",
    "clustering_coef = nx.algorithms.cluster.clustering(G)\n",
    "betweeness_centrality = nx.betweenness_centrality(G, k=50)\n",
    "degree = G.degree()\n",
    "\n",
    "# Create initial node features from that\n",
    "aug_emb = torch.ones(num_nodes, 5, dtype=torch.float64).to(device)\n",
    "for i in range(num_nodes):\n",
    "  aug_emb[i][0] = degree[i]\n",
    "  aug_emb[i][1] = pagerank[i]\n",
    "  aug_emb[i][2] = betweeness_centrality[i]\n",
    "  aug_emb[i][3] = pagerank[i]\n",
    "  aug_emb[i][4] = 1.0\n",
    "aug_emb = aug_emb.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTyaBIsmA9Ji"
   },
   "source": [
    "Let's now use these new node features and kick-off training. As we now have richer (and distinct) initial node features, we may not need to use as many GNN layers as before, which we experiment with below. Additionally, having seen the benefits of the `NeuralLinkPredictor`,  we continue to leverage it along with our base `SAGE` model.\n",
    "\n",
    "*This cell will take around 10 minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bzpaFHfHe-Z",
    "outputId": "6ffe4046-c7c1-4d3c-877f-bd71f72ee5e2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 11.7797\n",
      "Epoch 1 has loss 10.2298\n",
      "Epoch 2 has loss 9.8303\n",
      "Epoch 3 has loss 9.7739\n",
      "Epoch 4 has loss 9.5056\n",
      "Epoch 5 has loss 8.7571\n",
      "Epoch 6 has loss 8.1665\n",
      "Epoch 7 has loss 7.7742\n",
      "Epoch 8 has loss 7.6725\n",
      "Epoch 9 has loss 7.4331\n",
      "Epoch 10 has loss 7.3427\n",
      "Epoch 11 has loss 6.7041\n",
      "Epoch 12 has loss 6.5088\n",
      "Epoch 13 has loss 6.1485\n",
      "Epoch 14 has loss 5.9559\n",
      "Epoch 15 has loss 5.8623\n",
      "Epoch 16 has loss 5.9244\n",
      "Epoch 17 has loss 5.8425\n",
      "Epoch 18 has loss 5.684\n",
      "Epoch 19 has loss 5.7378\n",
      "Epoch 20 has loss 5.6137\n",
      "Epoch 21 has loss 5.5834\n",
      "Epoch 22 has loss 5.706\n",
      "Epoch 23 has loss 5.5933\n",
      "Epoch 24 has loss 5.5229\n",
      "Epoch 25 has loss 5.4564\n",
      "Epoch 26 has loss 5.4345\n",
      "Epoch 27 has loss 5.41\n",
      "Epoch 28 has loss 5.3603\n",
      "Epoch 29 has loss 5.3369\n",
      "Epoch 30 has loss 5.3842\n",
      "Epoch 31 has loss 5.4388\n",
      "Epoch 32 has loss 5.3477\n",
      "Epoch 33 has loss 5.3485\n",
      "Epoch 34 has loss 5.2593\n",
      "Epoch 35 has loss 5.2212\n",
      "Epoch 36 has loss 5.2423\n",
      "Epoch 37 has loss 5.1461\n",
      "Epoch 38 has loss 5.114\n",
      "Epoch 39 has loss 5.1362\n",
      "Epoch 40 has loss 5.1128\n",
      "Epoch 41 has loss 5.0049\n",
      "Epoch 42 has loss 4.8696\n",
      "Epoch 43 has loss 4.8449\n",
      "Epoch 44 has loss 4.8897\n",
      "Epoch 45 has loss 4.7727\n",
      "Epoch 46 has loss 4.7241\n",
      "Epoch 47 has loss 4.7231\n",
      "Epoch 48 has loss 4.5788\n",
      "Epoch 49 has loss 4.6661\n",
      "Epoch 50 has loss 4.7024\n",
      "Epoch 51 has loss 4.6975\n",
      "Epoch 52 has loss 4.5479\n",
      "Epoch 53 has loss 4.4333\n",
      "Epoch 54 has loss 4.5626\n",
      "Epoch 55 has loss 4.6498\n",
      "Epoch 56 has loss 4.5609\n",
      "Epoch 57 has loss 4.5381\n",
      "Epoch 58 has loss 4.4513\n",
      "Epoch 59 has loss 4.3653\n",
      "Epoch 60 has loss 4.334\n",
      "Epoch 61 has loss 4.2289\n",
      "Epoch 62 has loss 4.18\n",
      "Epoch 63 has loss 4.1603\n",
      "Epoch 64 has loss 4.2379\n",
      "Epoch 65 has loss 4.4009\n",
      "Epoch 66 has loss 4.35\n",
      "Epoch 67 has loss 4.1532\n",
      "Epoch 68 has loss 4.1439\n",
      "Epoch 69 has loss 4.1017\n",
      "Epoch 70 has loss 4.1232\n",
      "Epoch 71 has loss 4.2166\n",
      "Epoch 72 has loss 4.0701\n",
      "Epoch 73 has loss 4.0092\n",
      "Epoch 74 has loss 3.9779\n",
      "Epoch 75 has loss 4.046\n",
      "Epoch 76 has loss 4.1065\n",
      "Epoch 77 has loss 4.029\n",
      "Epoch 78 has loss 4.0107\n",
      "Epoch 79 has loss 3.9746\n",
      "Epoch 80 has loss 3.8507\n",
      "Epoch 81 has loss 4.0419\n",
      "Epoch 82 has loss 3.8358\n",
      "Epoch 83 has loss 3.9053\n",
      "Epoch 84 has loss 3.8688\n",
      "Epoch 85 has loss 3.9805\n",
      "Epoch 86 has loss 3.8355\n",
      "Epoch 87 has loss 3.7894\n",
      "Epoch 88 has loss 3.7943\n",
      "Epoch 89 has loss 3.7675\n",
      "Epoch 90 has loss 3.7422\n",
      "Epoch 91 has loss 3.7018\n",
      "Epoch 92 has loss 3.7113\n",
      "Epoch 93 has loss 3.8526\n",
      "Epoch 94 has loss 3.6756\n",
      "Epoch 95 has loss 3.7001\n",
      "Epoch 96 has loss 3.743\n",
      "Epoch 97 has loss 3.7757\n",
      "Epoch 98 has loss 3.7022\n",
      "Epoch 99 has loss 3.6666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9167,\n",
       " 'Hits@10': 0.24270913708245623,\n",
       " 'Hits@20': 0.29468345706387794,\n",
       " 'Hits@30': 0.3067293934331668,\n",
       " 'Hits@40': 0.3067293934331668,\n",
       " 'Hits@50': 0.3067293934331668}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAGE(5, hidden_dimension, hidden_dimension, 5, 0.5).to(device)\n",
    "predictor = NeuralLinkPredictor(hidden_dimension, hidden_dimension, 1, 4, 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, aug_emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 100)\n",
    "test(model, predictor, aug_emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef09V4XoUcUv"
   },
   "source": [
    "There is a bit of variability between runs, but you should see that leveraging our `aug_emb` yields similar, and sometimes even better performance than using our constant features with the `NeuralLinkPredictor`! Just with some rudimentary node features, we are seeing solid performance. A more exhaustive feature search would likely yield even better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Z3au11ljIxB"
   },
   "source": [
    "## Distance Encoding / Edge Feature Augmentation\n",
    "Just as we added node features to this homogenous, feature-less graph, we can also add edge-level features. Incorporating them into our GNN is trickier, but gives us the opportunity to peel back the layers of PyG and implement not just our own GNN model, but our own `MessagePassing` layer!\n",
    "\n",
    "Prior work by [Lu et al.](https://github.com/lustoo/OGB_link_prediction/blob/main/Link%20prediction%20with%20structural%20information.pdf) found that distance encoding methods worked well for ogbl-ddi, as nodes that are estimated to be close together have a higher chance of being connected by an edge. We can incorporate the distances from each node to a set of anchor nodes and use those to estimate distances between any pairs of nodes. Rather than incorporate those distances during link prediction, we will instead directly factor those distances into our embeddings, treating the distances as edge features between nodes. Below, we present a slightly simplified spin on the current state-of-the-art approach developed in the aforementioned paper, which allows for easier understanding and a better illustration of how to leverage PyG's custom `MessagePassing` framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Orvd4mjtj-5i"
   },
   "source": [
    "### Shortest Path Distances\n",
    "First, we need to calculate the distance of each node to a set of randomly sampled anchor nodes. This will serve as the foundation of the 'edge features' we will utilize in our custom `MessagePassing` layer.\n",
    "\n",
    "Below, we leverage NetworkX functionality to calculate the shortest path distances for each node. Each row in the `(num_nodes, K)`-shaped `spd` matrix contains the distances from the corresponding node to all K anchor nodes. We have set K = 200, but feel free to play around with the value to see what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qP9EEjQ2j873",
    "outputId": "ad3b44a2-c8fd-49a5-f7b0-50513e1cdcd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 2.,  ..., 2., 2., 2.],\n",
       "        [2., 1., 2.,  ..., 3., 2., 3.],\n",
       "        [3., 1., 3.,  ..., 3., 2., 3.],\n",
       "        ...,\n",
       "        [3., 3., 3.,  ..., 3., 4., 4.],\n",
       "        [2., 3., 2.,  ..., 2., 3., 2.],\n",
       "        [2., 3., 2.,  ..., 2., 3., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 200\n",
    "sampled_nodes = sorted(random.sample(G.nodes, K))\n",
    "\n",
    "spd = torch.ones(num_nodes, K, dtype=torch.float64).to(device)\n",
    "for k in range(K):\n",
    "  distance_from_sample_k_to_all_nodes = nx.shortest_path_length(G, source=sampled_nodes[k])\n",
    "  for node in distance_from_sample_k_to_all_nodes:\n",
    "    spd[node][k] = distance_from_sample_k_to_all_nodes[node]\n",
    "spd = spd.float()\n",
    "spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dutb3hhQgxhk"
   },
   "source": [
    "### Custom MessagePassing Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_4Q00NQaVI6"
   },
   "source": [
    "Now it's time to define our own `MessagePassing` layer! We have been leveraging PyG's built-in `SAGEConv` up until now. However, PyG has rich functionality for building your own `MessagePassing` layer, as seen in the documentation: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html.\n",
    "\n",
    "Our implementation draws inspiration from https://github.com/lustoo/OGB_link_prediction/blob/main/DDI/link_pred_ddi_graphsage_edge.py, which itself heavily builds upon the [source](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/sage_conv.html#SAGEConv) `SAGEConv` implementation.\n",
    "\n",
    "At a high-level, for every edge, we take the shortest-path distances for the two nodes, *i* and *j*, it connects and sum/average those to get an estimate of distance - which we treat as our edge feature. These edge features are then transformed using a linear layer and added to the message being passed from *j* to *i*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-B3hu2c7JSj"
   },
   "outputs": [],
   "source": [
    "class SAGEConvWithEdgesConceptual(MessagePassing):\n",
    "    def __init__(self, in_channels,\n",
    "                 out_channels, normalize = False,\n",
    "                 root_weight = True,\n",
    "                 bias = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(SAGEConvWithEdges, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = torch.nn.Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_e = torch.nn.Linear(1, in_channels[0], bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = torch.nn.Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_e.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, spd, size = None):\n",
    "        if isinstance(x, Tensor):\n",
    "            x = (x, x)\n",
    "        out = self.propagate(edge_index, x=x, spd=spd)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "          out = F.normalize(out, p=2., dim=-1)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, spd_i, spd_j):\n",
    "        dist_mean = torch.mean(spd_i + spd_j, 1, True)\n",
    "        return F.relu(x_j + self.lin_e(dist_mean))\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVXP0Nhs7Uv4"
   },
   "source": [
    "Unfortunately, Google Colab's variable/limited GPU memory is unreliable when it comes to the big matrix multiplication involving 2 million edges needed to perform this operation as conceptually desired. Instead, we apply a linear transformation to the average of each node's shortest path distances first. We then add those pre-transformed distances together for each edge, which are then added to the message being passed from *j* to *i*, as before. While this is not quite what we wanted, it gets us reasonably close and is far more reliable on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhYYn51TnLqP"
   },
   "outputs": [],
   "source": [
    "class SAGEConvWithEdges(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels,\n",
    "                 out_channels, normalize = False,\n",
    "                 root_weight = True,\n",
    "                 bias = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(SAGEConvWithEdges, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = torch.nn.Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_e = torch.nn.Linear(1, in_channels[0])\n",
    "        if self.root_weight:\n",
    "            self.lin_r = torch.nn.Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_e.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, spd, size = None):\n",
    "        if isinstance(x, Tensor):\n",
    "            x = (x, x)\n",
    "\n",
    "        spd = torch.sum(spd, dim=1, keepdim=True) / spd.shape[1]\n",
    "        spd = self.lin_e(spd)\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, spd=spd)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, spd_i, spd_j):\n",
    "        dist_mean = F.relu(spd_i + spd_j)\n",
    "        return x_j + dist_mean\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7_SecjwfIkJ"
   },
   "source": [
    "With our custom `MessagePassing` layer `SAGEConvWithEdges` defined, we now build a new GNN model that takes advantage of it. This is very similar to our `SAGE` base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzjPcUj7Cudx"
   },
   "outputs": [],
   "source": [
    "class EdgeSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout, aggr=\"mean\"):\n",
    "        super(EdgeSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConvWithEdges(in_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConvWithEdges(hidden_channels, hidden_channels, normalize=True, aggr=aggr))\n",
    "        self.convs.append(SAGEConvWithEdges(hidden_channels, out_channels, normalize=True, aggr=aggr))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, spd):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index, spd)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index, spd)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weG2gwkT8GWf"
   },
   "source": [
    "With our model defined, let's train and evaluate it, again leveraging our successful `NeuralLinkPredictor` alongside it. Unfortunately, Google Colab GPU limits continue to be an issue, even with the tweaks made to our model, so we have to significantly reduce the `hidden_dimension` size.\n",
    "\n",
    "*This cell will take around 1 hour to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHQS58-7dgM6",
    "outputId": "f482e488-5dd7-4f43-9ebb-187b16a22b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 11.768\n",
      "Epoch 1 has loss 10.9924\n",
      "Epoch 2 has loss 9.3468\n",
      "Epoch 3 has loss 9.8698\n",
      "Epoch 4 has loss 9.1261\n"
     ]
    }
   ],
   "source": [
    "hidden_dimension = 64\n",
    "model = EdgeSAGE(1, hidden_dimension, hidden_dimension, 7, 0.5, aggr=\"add\").to(device)\n",
    "predictor = NeuralLinkPredictor(hidden_dimension, hidden_dimension, 1, 4, 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.005)\n",
    "train(model, predictor, emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 100, edge_model=True, spd=spd)\n",
    "test(model, predictor, emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024, edge_model=True, spd=spd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh8fYkpo9c5m"
   },
   "source": [
    "Even with all of our compromises due to GPU limits, distance encoding still yields a somewhat reasonable model, especially given we had to significantly reduce its expressiveness by shrinking the embedding size. As seen in the [ogbl-ddi leaderboard](https://ogb.stanford.edu/docs/leader_linkprop/#ogbl-ddi), distance encoding methods yield the best results for this dataset. Access to more robust GPU capability would certainly yield better results with this approach.\n",
    "\n",
    "Regardless, this journey has served its purpose and introduced readers to how PyG allows custom `MessagePassing` layers to be created!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWmj10CGgpkr"
   },
   "source": [
    "## Conclusion\n",
    "We've come a long way in this Colab (and accompanying blog post). We have learned about exploring graphs using NetworkX, setting up baseline GraphSage models for Graph Machine Learning in PyG, and learned a myriad of techniques to try to make them stronger: skip-connections, post-processing layers, neural link predictors, node feature augmentation, and even distance encoding/edge feature augmentation. We hope you learned a lot! As a parting gift, you can run the cell below to train our most reliable technique, the `NeuralLinkPredictor`, for 500 epochs and evaluate it on our test set. Beyond that, we encourage you to try mixing and matching different techniques in this Colab, or experimenting with your own!\n",
    "\n",
    "*This cell will take around 1 hour to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kxhYF6UuNMs",
    "outputId": "5d13fda0-3c2c-40ef-9246-3c6b3596aa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 11.5898\n",
      "Epoch 1 has loss 9.581\n",
      "Epoch 2 has loss 8.4411\n",
      "Epoch 3 has loss 8.0946\n",
      "Epoch 4 has loss 7.6962\n",
      "Epoch 5 has loss 7.5717\n",
      "Epoch 6 has loss 7.5556\n",
      "Epoch 7 has loss 7.4502\n",
      "Epoch 8 has loss 7.4398\n",
      "Epoch 9 has loss 7.1811\n",
      "Epoch 10 has loss 6.9066\n",
      "Epoch 11 has loss 6.7268\n",
      "Epoch 12 has loss 6.1716\n",
      "Epoch 13 has loss 5.8921\n",
      "Epoch 14 has loss 5.7989\n",
      "Epoch 15 has loss 5.6197\n",
      "Epoch 16 has loss 5.6727\n",
      "Epoch 17 has loss 5.4816\n",
      "Epoch 18 has loss 5.4155\n",
      "Epoch 19 has loss 5.355\n",
      "Epoch 20 has loss 5.2154\n",
      "Epoch 21 has loss 5.0505\n",
      "Epoch 22 has loss 4.9668\n",
      "Epoch 23 has loss 4.8578\n",
      "Epoch 24 has loss 4.8276\n",
      "Epoch 25 has loss 4.7597\n",
      "Epoch 26 has loss 4.8681\n",
      "Epoch 27 has loss 4.6833\n",
      "Epoch 28 has loss 4.7267\n",
      "Epoch 29 has loss 4.5759\n",
      "Epoch 30 has loss 4.5262\n",
      "Epoch 31 has loss 4.4665\n",
      "Epoch 32 has loss 4.3046\n",
      "Epoch 33 has loss 4.3187\n",
      "Epoch 34 has loss 4.3806\n",
      "Epoch 35 has loss 4.3238\n",
      "Epoch 36 has loss 4.2371\n",
      "Epoch 37 has loss 4.2225\n",
      "Epoch 38 has loss 4.1874\n",
      "Epoch 39 has loss 4.2184\n",
      "Epoch 40 has loss 4.1612\n",
      "Epoch 41 has loss 4.1521\n",
      "Epoch 42 has loss 4.1275\n",
      "Epoch 43 has loss 3.9882\n",
      "Epoch 44 has loss 3.9701\n",
      "Epoch 45 has loss 3.8884\n",
      "Epoch 46 has loss 3.9538\n",
      "Epoch 47 has loss 3.9036\n",
      "Epoch 48 has loss 3.9192\n",
      "Epoch 49 has loss 3.7996\n",
      "Epoch 50 has loss 3.7968\n",
      "Epoch 51 has loss 3.7954\n",
      "Epoch 52 has loss 3.7213\n",
      "Epoch 53 has loss 3.7485\n",
      "Epoch 54 has loss 3.8035\n",
      "Epoch 55 has loss 3.6997\n",
      "Epoch 56 has loss 3.6948\n",
      "Epoch 57 has loss 3.6781\n",
      "Epoch 58 has loss 3.6388\n",
      "Epoch 59 has loss 3.6626\n",
      "Epoch 60 has loss 3.6218\n",
      "Epoch 61 has loss 3.6784\n",
      "Epoch 62 has loss 3.5926\n",
      "Epoch 63 has loss 3.5422\n",
      "Epoch 64 has loss 3.5653\n",
      "Epoch 65 has loss 3.4715\n",
      "Epoch 66 has loss 3.5522\n",
      "Epoch 67 has loss 3.4933\n",
      "Epoch 68 has loss 3.5079\n",
      "Epoch 69 has loss 3.4596\n",
      "Epoch 70 has loss 3.4334\n",
      "Epoch 71 has loss 3.4129\n",
      "Epoch 72 has loss 3.3761\n",
      "Epoch 73 has loss 3.3844\n",
      "Epoch 74 has loss 3.484\n",
      "Epoch 75 has loss 3.4391\n",
      "Epoch 76 has loss 3.4401\n",
      "Epoch 77 has loss 3.3665\n",
      "Epoch 78 has loss 3.3867\n",
      "Epoch 79 has loss 3.376\n",
      "Epoch 80 has loss 3.3757\n",
      "Epoch 81 has loss 3.2472\n",
      "Epoch 82 has loss 3.2929\n",
      "Epoch 83 has loss 3.2511\n",
      "Epoch 84 has loss 3.2231\n",
      "Epoch 85 has loss 3.1815\n",
      "Epoch 86 has loss 3.2961\n",
      "Epoch 87 has loss 3.2356\n",
      "Epoch 88 has loss 3.2041\n",
      "Epoch 89 has loss 3.2947\n",
      "Epoch 90 has loss 3.2634\n",
      "Epoch 91 has loss 3.2024\n",
      "Epoch 92 has loss 3.1366\n",
      "Epoch 93 has loss 3.1291\n",
      "Epoch 94 has loss 3.1455\n",
      "Epoch 95 has loss 3.112\n",
      "Epoch 96 has loss 3.1646\n",
      "Epoch 97 has loss 3.2018\n",
      "Epoch 98 has loss 3.1982\n",
      "Epoch 99 has loss 3.0717\n",
      "Epoch 100 has loss 3.0465\n",
      "Epoch 101 has loss 3.0124\n",
      "Epoch 102 has loss 3.0857\n",
      "Epoch 103 has loss 3.0241\n",
      "Epoch 104 has loss 3.0887\n",
      "Epoch 105 has loss 3.0573\n",
      "Epoch 106 has loss 2.9875\n",
      "Epoch 107 has loss 2.9617\n",
      "Epoch 108 has loss 3.0284\n",
      "Epoch 109 has loss 2.9813\n",
      "Epoch 110 has loss 2.9804\n",
      "Epoch 111 has loss 2.9793\n",
      "Epoch 112 has loss 2.9696\n",
      "Epoch 113 has loss 3.0352\n",
      "Epoch 114 has loss 2.9343\n",
      "Epoch 115 has loss 2.9222\n",
      "Epoch 116 has loss 2.9115\n",
      "Epoch 117 has loss 2.9272\n",
      "Epoch 118 has loss 2.8569\n",
      "Epoch 119 has loss 2.8734\n",
      "Epoch 120 has loss 2.8959\n",
      "Epoch 121 has loss 3.0224\n",
      "Epoch 122 has loss 2.9493\n",
      "Epoch 123 has loss 2.8738\n",
      "Epoch 124 has loss 2.8297\n",
      "Epoch 125 has loss 2.8409\n",
      "Epoch 126 has loss 2.8208\n",
      "Epoch 127 has loss 2.7771\n",
      "Epoch 128 has loss 2.7361\n",
      "Epoch 129 has loss 2.7822\n",
      "Epoch 130 has loss 2.7865\n",
      "Epoch 131 has loss 2.8289\n",
      "Epoch 132 has loss 2.7896\n",
      "Epoch 133 has loss 2.7294\n",
      "Epoch 134 has loss 2.7824\n",
      "Epoch 135 has loss 2.7677\n",
      "Epoch 136 has loss 2.7301\n",
      "Epoch 137 has loss 2.721\n",
      "Epoch 138 has loss 2.7277\n",
      "Epoch 139 has loss 2.6924\n",
      "Epoch 140 has loss 2.7778\n",
      "Epoch 141 has loss 2.874\n",
      "Epoch 142 has loss 2.7843\n",
      "Epoch 143 has loss 2.7447\n",
      "Epoch 144 has loss 2.7568\n",
      "Epoch 145 has loss 2.6795\n",
      "Epoch 146 has loss 2.8027\n",
      "Epoch 147 has loss 2.8031\n",
      "Epoch 148 has loss 2.7424\n",
      "Epoch 149 has loss 2.6579\n",
      "Epoch 150 has loss 2.691\n",
      "Epoch 151 has loss 2.6888\n",
      "Epoch 152 has loss 2.6849\n",
      "Epoch 153 has loss 2.6381\n",
      "Epoch 154 has loss 2.6432\n",
      "Epoch 155 has loss 2.6432\n",
      "Epoch 156 has loss 2.6354\n",
      "Epoch 157 has loss 2.5951\n",
      "Epoch 158 has loss 2.5521\n",
      "Epoch 159 has loss 2.5621\n",
      "Epoch 160 has loss 2.5403\n",
      "Epoch 161 has loss 2.5421\n",
      "Epoch 162 has loss 2.5305\n",
      "Epoch 163 has loss 2.5071\n",
      "Epoch 164 has loss 2.542\n",
      "Epoch 165 has loss 2.5743\n",
      "Epoch 166 has loss 2.6032\n",
      "Epoch 167 has loss 2.5203\n",
      "Epoch 168 has loss 2.5894\n",
      "Epoch 169 has loss 2.5546\n",
      "Epoch 170 has loss 2.5515\n",
      "Epoch 171 has loss 2.5175\n",
      "Epoch 172 has loss 2.5791\n",
      "Epoch 173 has loss 2.5272\n",
      "Epoch 174 has loss 2.5124\n",
      "Epoch 175 has loss 2.4924\n",
      "Epoch 176 has loss 2.4487\n",
      "Epoch 177 has loss 2.4788\n",
      "Epoch 178 has loss 2.4704\n",
      "Epoch 179 has loss 2.5438\n",
      "Epoch 180 has loss 2.571\n",
      "Epoch 181 has loss 2.4948\n",
      "Epoch 182 has loss 2.4493\n",
      "Epoch 183 has loss 2.4577\n",
      "Epoch 184 has loss 2.4421\n",
      "Epoch 185 has loss 2.4547\n",
      "Epoch 186 has loss 2.493\n",
      "Epoch 187 has loss 2.464\n",
      "Epoch 188 has loss 2.4585\n",
      "Epoch 189 has loss 2.4336\n",
      "Epoch 190 has loss 2.4306\n",
      "Epoch 191 has loss 2.466\n",
      "Epoch 192 has loss 2.4744\n",
      "Epoch 193 has loss 2.4204\n",
      "Epoch 194 has loss 2.4624\n",
      "Epoch 195 has loss 2.407\n",
      "Epoch 196 has loss 2.3937\n",
      "Epoch 197 has loss 2.4143\n",
      "Epoch 198 has loss 2.4188\n",
      "Epoch 199 has loss 2.4438\n",
      "Epoch 200 has loss 2.4034\n",
      "Epoch 201 has loss 2.3982\n",
      "Epoch 202 has loss 2.3731\n",
      "Epoch 203 has loss 2.3881\n",
      "Epoch 204 has loss 2.3481\n",
      "Epoch 205 has loss 2.374\n",
      "Epoch 206 has loss 2.3391\n",
      "Epoch 207 has loss 2.4301\n",
      "Epoch 208 has loss 2.4149\n",
      "Epoch 209 has loss 2.3517\n",
      "Epoch 210 has loss 2.4179\n",
      "Epoch 211 has loss 2.3813\n",
      "Epoch 212 has loss 2.3131\n",
      "Epoch 213 has loss 2.3266\n",
      "Epoch 214 has loss 2.3641\n",
      "Epoch 215 has loss 2.3254\n",
      "Epoch 216 has loss 2.3114\n",
      "Epoch 217 has loss 2.3932\n",
      "Epoch 218 has loss 2.3257\n",
      "Epoch 219 has loss 2.3482\n",
      "Epoch 220 has loss 2.2918\n",
      "Epoch 221 has loss 2.3036\n",
      "Epoch 222 has loss 2.2759\n",
      "Epoch 223 has loss 2.2951\n",
      "Epoch 224 has loss 2.2891\n",
      "Epoch 225 has loss 2.31\n",
      "Epoch 226 has loss 2.2735\n",
      "Epoch 227 has loss 2.2987\n",
      "Epoch 228 has loss 2.3118\n",
      "Epoch 229 has loss 2.2845\n",
      "Epoch 230 has loss 2.3776\n",
      "Epoch 231 has loss 2.2705\n",
      "Epoch 232 has loss 2.2491\n",
      "Epoch 233 has loss 2.3149\n",
      "Epoch 234 has loss 2.2969\n",
      "Epoch 235 has loss 2.2753\n",
      "Epoch 236 has loss 2.2406\n",
      "Epoch 237 has loss 2.2223\n",
      "Epoch 238 has loss 2.2184\n",
      "Epoch 239 has loss 2.2311\n",
      "Epoch 240 has loss 2.2346\n",
      "Epoch 241 has loss 2.2097\n",
      "Epoch 242 has loss 2.2205\n",
      "Epoch 243 has loss 2.2391\n",
      "Epoch 244 has loss 2.2006\n",
      "Epoch 245 has loss 2.1951\n",
      "Epoch 246 has loss 2.2318\n",
      "Epoch 247 has loss 2.2604\n",
      "Epoch 248 has loss 2.2183\n",
      "Epoch 249 has loss 2.2334\n",
      "Epoch 250 has loss 2.232\n",
      "Epoch 251 has loss 2.224\n",
      "Epoch 252 has loss 2.2102\n",
      "Epoch 253 has loss 2.1842\n",
      "Epoch 254 has loss 2.2826\n",
      "Epoch 255 has loss 2.2604\n",
      "Epoch 256 has loss 2.1887\n",
      "Epoch 257 has loss 2.1886\n",
      "Epoch 258 has loss 2.1699\n",
      "Epoch 259 has loss 2.1735\n",
      "Epoch 260 has loss 2.1614\n",
      "Epoch 261 has loss 2.2657\n",
      "Epoch 262 has loss 2.2114\n",
      "Epoch 263 has loss 2.1885\n",
      "Epoch 264 has loss 2.1878\n",
      "Epoch 265 has loss 2.155\n",
      "Epoch 266 has loss 2.1747\n",
      "Epoch 267 has loss 2.1576\n",
      "Epoch 268 has loss 2.2286\n",
      "Epoch 269 has loss 2.1512\n",
      "Epoch 270 has loss 2.1177\n",
      "Epoch 271 has loss 2.1305\n",
      "Epoch 272 has loss 2.1206\n",
      "Epoch 273 has loss 2.1316\n",
      "Epoch 274 has loss 2.1102\n",
      "Epoch 275 has loss 2.1154\n",
      "Epoch 276 has loss 2.124\n",
      "Epoch 277 has loss 2.12\n",
      "Epoch 278 has loss 2.1345\n",
      "Epoch 279 has loss 2.1359\n",
      "Epoch 280 has loss 2.1017\n",
      "Epoch 281 has loss 2.1164\n",
      "Epoch 282 has loss 2.1126\n",
      "Epoch 283 has loss 2.1374\n",
      "Epoch 284 has loss 2.222\n",
      "Epoch 285 has loss 2.194\n",
      "Epoch 286 has loss 2.1982\n",
      "Epoch 287 has loss 2.1347\n",
      "Epoch 288 has loss 2.0783\n",
      "Epoch 289 has loss 2.0597\n",
      "Epoch 290 has loss 2.1038\n",
      "Epoch 291 has loss 2.1118\n",
      "Epoch 292 has loss 2.0679\n",
      "Epoch 293 has loss 2.0789\n",
      "Epoch 294 has loss 2.0664\n",
      "Epoch 295 has loss 2.0616\n",
      "Epoch 296 has loss 2.0851\n",
      "Epoch 297 has loss 2.0761\n",
      "Epoch 298 has loss 2.1102\n",
      "Epoch 299 has loss 2.1114\n",
      "Epoch 300 has loss 2.0911\n",
      "Epoch 301 has loss 2.0596\n",
      "Epoch 302 has loss 2.0669\n",
      "Epoch 303 has loss 2.0537\n",
      "Epoch 304 has loss 2.0401\n",
      "Epoch 305 has loss 2.0363\n",
      "Epoch 306 has loss 2.0228\n",
      "Epoch 307 has loss 2.0176\n",
      "Epoch 308 has loss 2.0418\n",
      "Epoch 309 has loss 2.0515\n",
      "Epoch 310 has loss 2.0312\n",
      "Epoch 311 has loss 2.0711\n",
      "Epoch 312 has loss 2.0748\n",
      "Epoch 313 has loss 2.0505\n",
      "Epoch 314 has loss 2.0226\n",
      "Epoch 315 has loss 2.0277\n",
      "Epoch 316 has loss 2.0338\n",
      "Epoch 317 has loss 2.0605\n",
      "Epoch 318 has loss 2.0525\n",
      "Epoch 319 has loss 2.068\n",
      "Epoch 320 has loss 2.0633\n",
      "Epoch 321 has loss 2.0453\n",
      "Epoch 322 has loss 2.0263\n",
      "Epoch 323 has loss 2.0115\n",
      "Epoch 324 has loss 2.0138\n",
      "Epoch 325 has loss 2.0551\n",
      "Epoch 326 has loss 2.1323\n",
      "Epoch 327 has loss 2.0887\n",
      "Epoch 328 has loss 2.0234\n",
      "Epoch 329 has loss 2.0031\n",
      "Epoch 330 has loss 2.0134\n",
      "Epoch 331 has loss 2.0459\n",
      "Epoch 332 has loss 2.0031\n",
      "Epoch 333 has loss 1.9829\n",
      "Epoch 334 has loss 1.9673\n",
      "Epoch 335 has loss 1.9779\n",
      "Epoch 336 has loss 1.9919\n",
      "Epoch 337 has loss 2.0633\n",
      "Epoch 338 has loss 2.048\n",
      "Epoch 339 has loss 1.9996\n",
      "Epoch 340 has loss 1.9764\n",
      "Epoch 341 has loss 1.9834\n",
      "Epoch 342 has loss 1.9667\n",
      "Epoch 343 has loss 2.0064\n",
      "Epoch 344 has loss 2.0019\n",
      "Epoch 345 has loss 2.0036\n",
      "Epoch 346 has loss 1.9746\n",
      "Epoch 347 has loss 1.9797\n",
      "Epoch 348 has loss 1.9973\n",
      "Epoch 349 has loss 1.9844\n",
      "Epoch 350 has loss 1.986\n",
      "Epoch 351 has loss 1.9595\n",
      "Epoch 352 has loss 1.9689\n",
      "Epoch 353 has loss 1.9564\n",
      "Epoch 354 has loss 1.9522\n",
      "Epoch 355 has loss 1.9466\n",
      "Epoch 356 has loss 1.9422\n",
      "Epoch 357 has loss 1.9947\n",
      "Epoch 358 has loss 1.9813\n",
      "Epoch 359 has loss 1.9741\n",
      "Epoch 360 has loss 2.0203\n",
      "Epoch 361 has loss 1.9903\n",
      "Epoch 362 has loss 1.9679\n",
      "Epoch 363 has loss 2.0342\n",
      "Epoch 364 has loss 2.0859\n",
      "Epoch 365 has loss 2.003\n",
      "Epoch 366 has loss 1.9659\n",
      "Epoch 367 has loss 1.9668\n",
      "Epoch 368 has loss 1.9516\n",
      "Epoch 369 has loss 1.9273\n",
      "Epoch 370 has loss 1.9541\n",
      "Epoch 371 has loss 1.9724\n",
      "Epoch 372 has loss 1.9187\n",
      "Epoch 373 has loss 1.9245\n",
      "Epoch 374 has loss 1.949\n",
      "Epoch 375 has loss 1.9296\n",
      "Epoch 376 has loss 1.9524\n",
      "Epoch 377 has loss 1.9282\n",
      "Epoch 378 has loss 1.9367\n",
      "Epoch 379 has loss 1.92\n",
      "Epoch 380 has loss 1.9788\n",
      "Epoch 381 has loss 1.9229\n",
      "Epoch 382 has loss 1.908\n",
      "Epoch 383 has loss 1.9721\n",
      "Epoch 384 has loss 1.9108\n",
      "Epoch 385 has loss 1.9094\n",
      "Epoch 386 has loss 1.8964\n",
      "Epoch 387 has loss 1.8835\n",
      "Epoch 388 has loss 1.905\n",
      "Epoch 389 has loss 1.903\n",
      "Epoch 390 has loss 1.8901\n",
      "Epoch 391 has loss 1.9098\n",
      "Epoch 392 has loss 1.9427\n",
      "Epoch 393 has loss 1.8954\n",
      "Epoch 394 has loss 1.9308\n",
      "Epoch 395 has loss 1.9229\n",
      "Epoch 396 has loss 1.8869\n",
      "Epoch 397 has loss 1.8887\n",
      "Epoch 398 has loss 1.8859\n",
      "Epoch 399 has loss 1.8833\n",
      "Epoch 400 has loss 1.8627\n",
      "Epoch 401 has loss 1.9271\n",
      "Epoch 402 has loss 1.9328\n",
      "Epoch 403 has loss 1.8845\n",
      "Epoch 404 has loss 1.8936\n",
      "Epoch 405 has loss 1.8811\n",
      "Epoch 406 has loss 1.8861\n",
      "Epoch 407 has loss 1.9386\n",
      "Epoch 408 has loss 1.8797\n",
      "Epoch 409 has loss 1.9143\n",
      "Epoch 410 has loss 1.9021\n",
      "Epoch 411 has loss 1.8714\n",
      "Epoch 412 has loss 1.8862\n",
      "Epoch 413 has loss 1.8925\n",
      "Epoch 414 has loss 1.8731\n",
      "Epoch 415 has loss 1.8806\n",
      "Epoch 416 has loss 1.8598\n",
      "Epoch 417 has loss 1.8605\n",
      "Epoch 418 has loss 1.8456\n",
      "Epoch 419 has loss 1.882\n",
      "Epoch 420 has loss 1.8726\n",
      "Epoch 421 has loss 1.8713\n",
      "Epoch 422 has loss 1.9288\n",
      "Epoch 423 has loss 1.8924\n",
      "Epoch 424 has loss 1.8653\n",
      "Epoch 425 has loss 1.8397\n",
      "Epoch 426 has loss 1.8394\n",
      "Epoch 427 has loss 1.8972\n",
      "Epoch 428 has loss 1.8855\n",
      "Epoch 429 has loss 1.8628\n",
      "Epoch 430 has loss 1.863\n",
      "Epoch 431 has loss 1.921\n",
      "Epoch 432 has loss 1.8974\n",
      "Epoch 433 has loss 1.8446\n",
      "Epoch 434 has loss 1.8449\n",
      "Epoch 435 has loss 1.9103\n",
      "Epoch 436 has loss 1.9064\n",
      "Epoch 437 has loss 1.9002\n",
      "Epoch 438 has loss 1.8944\n",
      "Epoch 439 has loss 1.852\n",
      "Epoch 440 has loss 1.8477\n",
      "Epoch 441 has loss 1.833\n",
      "Epoch 442 has loss 1.8622\n",
      "Epoch 443 has loss 1.8614\n",
      "Epoch 444 has loss 1.8164\n",
      "Epoch 445 has loss 1.8925\n",
      "Epoch 446 has loss 1.865\n",
      "Epoch 447 has loss 1.8204\n",
      "Epoch 448 has loss 1.8036\n",
      "Epoch 449 has loss 1.8025\n",
      "Epoch 450 has loss 1.8666\n",
      "Epoch 451 has loss 1.8508\n",
      "Epoch 452 has loss 1.8123\n",
      "Epoch 453 has loss 1.8185\n",
      "Epoch 454 has loss 1.815\n",
      "Epoch 455 has loss 1.8133\n",
      "Epoch 456 has loss 1.8166\n",
      "Epoch 457 has loss 1.8082\n",
      "Epoch 458 has loss 1.8274\n",
      "Epoch 459 has loss 1.8054\n",
      "Epoch 460 has loss 1.8117\n",
      "Epoch 461 has loss 1.8481\n",
      "Epoch 462 has loss 1.8333\n",
      "Epoch 463 has loss 1.8302\n",
      "Epoch 464 has loss 1.8218\n",
      "Epoch 465 has loss 1.8543\n",
      "Epoch 466 has loss 1.865\n",
      "Epoch 467 has loss 1.8259\n",
      "Epoch 468 has loss 1.8034\n",
      "Epoch 469 has loss 1.797\n",
      "Epoch 470 has loss 1.7991\n",
      "Epoch 471 has loss 1.8114\n",
      "Epoch 472 has loss 1.8191\n",
      "Epoch 473 has loss 1.8749\n",
      "Epoch 474 has loss 1.8382\n",
      "Epoch 475 has loss 1.8294\n",
      "Epoch 476 has loss 1.8241\n",
      "Epoch 477 has loss 1.8178\n",
      "Epoch 478 has loss 1.7835\n",
      "Epoch 479 has loss 1.8082\n",
      "Epoch 480 has loss 1.8162\n",
      "Epoch 481 has loss 1.7958\n",
      "Epoch 482 has loss 1.8006\n",
      "Epoch 483 has loss 1.7932\n",
      "Epoch 484 has loss 1.7862\n",
      "Epoch 485 has loss 1.7839\n",
      "Epoch 486 has loss 1.8097\n",
      "Epoch 487 has loss 1.8124\n",
      "Epoch 488 has loss 1.8112\n",
      "Epoch 489 has loss 1.8067\n",
      "Epoch 490 has loss 1.7949\n",
      "Epoch 491 has loss 1.8068\n",
      "Epoch 492 has loss 1.8093\n",
      "Epoch 493 has loss 1.7919\n",
      "Epoch 494 has loss 1.7873\n",
      "Epoch 495 has loss 1.8174\n",
      "Epoch 496 has loss 1.7912\n",
      "Epoch 497 has loss 1.7734\n",
      "Epoch 498 has loss 1.7993\n",
      "Epoch 499 has loss 1.782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9817,\n",
       " 'Hits@10': 0.29468345706387794,\n",
       " 'Hits@20': 0.4056214369723348,\n",
       " 'Hits@30': 0.5194660234176599,\n",
       " 'Hits@40': 0.5725490489853097,\n",
       " 'Hits@50': 0.605585478953322}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dimension = 256\n",
    "model = SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = NeuralLinkPredictor(hidden_dimension, hidden_dimension, 1, 4, 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.005)\n",
    "train(model, predictor, emb, adj_t, split_edge, torch.nn.BCELoss(),\n",
    "      optimizer, 64 * 1024, 500)\n",
    "test(model, predictor, emb, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deuD-TPxuSns",
    "outputId": "65ee7c50-0fbd-4e5a-a93a-d8fc148ec794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.982,\n",
       " 'Hits@10': 0.2702994254208212,\n",
       " 'Hits@20': 0.32144970746653284,\n",
       " 'Hits@30': 0.4310242791540876,\n",
       " 'Hits@40': 0.5039216714485838,\n",
       " 'Hits@50': 0.5361865022586131}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, predictor, emb, adj_t, split_edge[\"test\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
